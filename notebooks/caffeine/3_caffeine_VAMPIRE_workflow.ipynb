{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAMPIRE WORKFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: To split images into quadrants, pick training and testing image sets, and in the future run the full VAMPIRE workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited: October 28th, 2021 to specifically refer to Phuong's BEV Treatment data and split them for VAMPIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Import necessary packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from numpy.linalg import inv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.segmentation import clear_border\n",
    "import skimage\n",
    "import tifffile as tiff\n",
    "import vampire\n",
    "from os.path import isfile, join\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: User Inputs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Step:\n",
    "Beginning with already segmented images saved as .npy arrays from the \"2_Phuong_collab_segmentation.ipynb\" Jupyter Notebook also within this folder. \n",
    "\n",
    "Not a blind study. \n",
    "\n",
    "Images already exist in a folder tree based on the overall slice treatment time and then the group subset for example:\n",
    "\n",
    "48_hr_exposure_time > (1) BEV_treatment (2) healthy_control (3) OGD_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file names should be in the current working directory\n",
    "folder_location = '/Users/nelsschimek/Documents/nancelab/Data/caffeine'\n",
    "\n",
    "file_type_init = '.npy'\n",
    "\n",
    "slice_number = 4\n",
    "random_state_num = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5: Getting the List of Images to Split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/'\n",
    "file_list = [f for f in os.listdir(my_path) if isfile(join(my_path, f)) and '.tif' in f]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "\n",
    "    new_array = np.load('/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/test/' + file)\n",
    "\n",
    "    colored_array = new_array.astype(np.uint8)*255\n",
    "\n",
    "    output_path = '/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/test/' + file[:-4] + '.tif'\n",
    "\n",
    "    tiff.imwrite(output_path, colored_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 4: Choose training and testing data sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttsplit_list_files = []\n",
    "# for folders in folder_list:\n",
    "#     arr = os.listdir(str(folder_location + '/' + folders))\n",
    "#     subfolder_list = np.asarray(arr)\n",
    "#     subfolder_list = [ x for x in subfolder_list if \"DS\" not in x]\n",
    "#     subfolder_list = [ x for x in subfolder_list if \".npy\" not in x]\n",
    "#     for subfolders in subfolder_list:\n",
    "#         print(subfolders)\n",
    "#         arr = os.listdir(str(folder_location + '/' + folders + '/' + subfolders))\n",
    "#         files_list = np.asarray(arr)\n",
    "#         files_list = [ x for x in files_list if \"DS\" not in x]\n",
    "#         files_list = [ x for x in files_list if \"quad\" in x]\n",
    "#         X_train, X_test= train_test_split(files_list, test_size=0.20, random_state=random_state_num)\n",
    "#         for files in files_list:\n",
    "#             if files in X_train[:]:\n",
    "#                 shutil.move(str(folder_location + '/' + folders + '/' + subfolders + '/' + files), '/Users/nelsschimek/Documents/nancelab/vampire_work/caffeine/train')\n",
    "#             else:\n",
    "#                 shutil.move(str(folder_location + '/' + folders + '/' + subfolders + '/' + files), '/Users/nelsschimek/Documents/nancelab/vampire_work/caffeine/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step Y: Renaming the data sets according to VAMPIRE naming mechanism*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train1 = os.listdir('/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/train')\n",
    "file_list_train1 = np.asarray(arr_train1)\n",
    "file_list_train1 = [ x for x in file_list_train1 if \"DS\" not in x]\n",
    "file_list_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_number= 1\n",
    "for names in file_list_train1:\n",
    "    print(names)\n",
    "    \n",
    "    file_location = str('/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/train/' + names)\n",
    "    array = np.load(file_location)\n",
    "    im = Image.fromarray(array)\n",
    "    \n",
    "    if im_number < 10:\n",
    "        im.save(str('/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/train/' + names[:-4] + 'xy' + '0' + str(im_number) + 'c1.png'))\n",
    "        \n",
    "    else:\n",
    "        im.save(str('/Users/nelsschimek/Documents/nancelab/Data/caffeine/cortex/train/' + names[:-4] + 'xy' + str(im_number) + 'c1.png'))\n",
    "        \n",
    "    \n",
    "    im_number +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Splitting the test group into the appropriate conditions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_number= 1\n",
    "for names in file_list_test:\n",
    "    print(names)\n",
    "    \n",
    "    file_location = str('/Users/nelsschimek/Documents/nancelab/vampire_work/caffeine/test/' + names)\n",
    "    array = np.load(file_location)\n",
    "    im = Image.fromarray(array)\n",
    "    \n",
    "    if im_number < 10:\n",
    "        im.save(str('/Users/nelsschimek/Documents/nancelab/vampire_work/caffeine/test/' + names[:-4] + 'xy' + '0' + str(im_number) + 'c1.png'))\n",
    "        \n",
    "    else:\n",
    "        im.save(str('/Users/nelsschimek/Documents/nancelab/vampire_work/caffeine/test/' + names[:-4] + 'xy' + str(im_number) + 'c1.png'))\n",
    "        \n",
    "    \n",
    "    im_number +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the information necessary for VAMPIRE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments = ['treatment_A', 'treatment_B', 'treatment_C', 'treatment_D', 'treatment_E']\n",
    "groups = ['cortex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set_path = '/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs'\n",
    "\n",
    "vampire.extraction.extract_properties(image_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_info_df = pd.DataFrame({\n",
    "    'img_set_path': [image_set_path],\n",
    "    'output_path': [image_set_path],\n",
    "    'model_name': ['li'],\n",
    "    'num_points': [50],\n",
    "    'num_clusters': [5],\n",
    "    'num_pc': [np.nan]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vampire.quickstart.fit_models(build_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs', 'model_li_(50_5_38)__.pickle')\n",
    "vampire_model = vampire.util.read_pickle(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'hippocampus'\n",
    "\n",
    "apply_info_df = pd.DataFrame({\n",
    "    'img_set_path': [f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_A/converted_tiffs/',\n",
    "                     f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_B/converted_tiffs/',\n",
    "                     f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_C/converted_tiffs/',\n",
    "                     f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_D/converted_tiffs/',\n",
    "                     f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_E/converted_tiffs/'],\n",
    "    'model_path': ['/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs/model_li_(50_5_38)__.pickle',\n",
    "                   '/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs/model_li_(50_5_38)__.pickle',\n",
    "                   '/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs/model_li_(50_5_38)__.pickle',\n",
    "                   '/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs/model_li_(50_5_38)__.pickle',\n",
    "                   '/Users/nelsschimek/Documents/nancelab/Data/caffeine/training/converted_tiffs/model_li_(50_5_38)__.pickle'],\n",
    "    'output_path': [f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_A/',\n",
    "                    f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_B/',\n",
    "                    f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_C/',\n",
    "                    f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_D/',\n",
    "                    f'/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/{region}/treatment_E/'],\n",
    "    'img_set_name': [f'li_{region}_treatment_A',\n",
    "                     f'li_{region}_treatment_B',\n",
    "                     f'li_{region}_treatment_C',\n",
    "                     f'li_{region}_treatment_D',\n",
    "                     f'li_{region}_treatment_E'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_info_df['img_set_path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vampire.quickstart.transform_datasets(apply_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_path = os.path.join('/Users/nelsschimek/Documents/nancelab/Data/caffeine/testing/cortex/treatment_A', 'apply-properties_li_on_li_cortex_treatment_A_(50_5_38)__.pickle')\n",
    "properties_df = vampire.util.read_pickle(properties_path)\n",
    "properties_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vampire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
